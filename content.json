{"meta":{"title":"HuangheheTech","subtitle":"","description":"huanghehe happy forever","author":"Huang He","url":"https://HeHeHuang.github.io","root":"/"},"pages":[{"title":"Personal Information","date":"2022-09-28T12:15:06.212Z","updated":"2022-09-28T12:15:06.200Z","comments":false,"path":"about/index.html","permalink":"https://hehehuang.github.io/about/index.html","excerpt":"","text":"HUANGHESUMMARYMaster of Technology graduate with Data scientist experience in time series predictive modelling and data mining. Skilled in machine learning, NLP, deep learning, statistics, problem solving, and programming. Seeking to increase data and model efficiency for Company. 4+ years of software engineer experience in IT industry that involved developing, testing, and maintaining enterprise healthcare applications achieving 100% client satisfaction. KEY SKILLS Data Analysis &amp; Data Visualization &amp; Big Data analytic Programming Language: Python, scikit-learn, PyTorch, Spark, Hadoop, R Programming, HTML, SQL, .NET, C# Database&#x2F;Server: MySQL, Oracle, MongoDB NLP (Deep Learning)Machine Learning Agile MethodologiesPMP WORKING EXPERIENCEData Scientist Created and presented Arima models to forecast influenza vaccine consumption for procurement team for better decision making Created and presented Arima models to forecast influenza vaccine consumption for different polyclinics in SHP for better manpower arrangement by using R, JMP and Python Used Streamlit to Create Web application for user to upload data to do forecasting accurately Software Engineer&#x2F; Application Consultant Provided IT support services, troubleshooting and system operation. Quickly solved production issues with 95% successCollaborated with stakeholders to identify requirements and recommend solutions to address business needs Translated business requirements into functional requirements for development teams in India Monitored and controlled work from India team and conducted SIT, UAT with stakeholders Used Asp.net, Asp.net MVC, oracle to develop, test and maintain medical healthcare system and, achieved 100% client satisfaction and on-time completion Software Engineer Used unity3D and C# to make VR project which allows customers to view the department in detail Developed a simple mobile app by using web service, SQL and Telerik Developed functions for website by using c#, ado.net"},{"title":"书单","date":"2022-09-24T10:40:39.161Z","updated":"2022-09-21T05:03:10.207Z","comments":false,"path":"books/index.html","permalink":"https://hehehuang.github.io/books/index.html","excerpt":"","text":""},{"title":"分类","date":"2022-09-21T09:10:16.325Z","updated":"2022-09-21T05:03:10.208Z","comments":false,"path":"categories/index.html","permalink":"https://hehehuang.github.io/categories/index.html","excerpt":"","text":""},{"title":"links","date":"2022-09-28T11:58:44.326Z","updated":"2022-09-28T11:58:44.310Z","comments":false,"path":"links/index.html","permalink":"https://hehehuang.github.io/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2022-09-24T16:41:17.610Z","updated":"2022-09-21T05:03:10.208Z","comments":false,"path":"repository/index.html","permalink":"https://hehehuang.github.io/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2022-09-24T09:44:30.595Z","updated":"2022-09-24T09:44:30.582Z","comments":false,"path":"tags/index.html","permalink":"https://hehehuang.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Spark ML Case","slug":"Spark-ML-Case","date":"2022-09-26T09:21:53.000Z","updated":"2022-09-26T09:21:53.804Z","comments":true,"path":"2022/09/26/Spark-ML-Case/","link":"","permalink":"https://hehehuang.github.io/2022/09/26/Spark-ML-Case/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"NLP for DeepLearning","slug":"NLP-for-DeepLearning","date":"2022-09-24T10:29:33.000Z","updated":"2022-09-24T10:30:22.233Z","comments":true,"path":"2022/09/24/NLP-for-DeepLearning/","link":"","permalink":"https://hehehuang.github.io/2022/09/24/NLP-for-DeepLearning/","excerpt":"","text":"","categories":[{"name":"NLP","slug":"NLP","permalink":"https://hehehuang.github.io/categories/NLP/"}],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://hehehuang.github.io/tags/Deep-Learning/"}]},{"title":"English Weekly Plan","slug":"English-Weekly-Plan","date":"2022-09-24T09:45:12.000Z","updated":"2022-09-24T10:01:15.068Z","comments":true,"path":"2022/09/24/English-Weekly-Plan/","link":"","permalink":"https://hehehuang.github.io/2022/09/24/English-Weekly-Plan/","excerpt":"","text":"THINGS YOU WILL NEED: 1 hour per day (30 minutes will work as well). a notebook and a pen to write down new vocabulary each day. an English song. an English a book. an English TV show. MONDAYS (Spend 30-40 minutes Reading) Read your book. Read the news. Read an article on http://simple.wikipedia.com Write down some new words in your notebook with their definition. Spend the rest of your hour: – Reading out loud from your book – Writing out some passages from your book. – Listening to the audiobook of your book. – Using Duolingo or other learning apps. TUESDAYS (Spend 30-40 minutes Writing) Write what you did yesterday, today, and tomorrow in your notebook. Write a few comments on Youtube videos. Write some sentences about what you like and dislike about your song, your book, and your TV show. Write a summary of what you have read in your book the day before. Put some new words in your dictionary. Spend the rest of your hour: – Reading what you have written. – Listening to what you have written by pasting your writing into Google translate and have it read it to you. – Reading what you have written out loud. – Using Duolingo or other learning apps. WEDNESDAYS (Spend 30-40 minutes Listening): Watch your TV show. Listen to your song. Listen to the Audiobook of your book if you have it. Watch a few Youtube videos. Put new words in your dictionary. Spend the rest of your hour: – Read about your TV show. – Write about how your song makes you feel. – Mimic or shadow people from your TV show. – Sing along to your song. THURSDAYS (Spend 30-40 minutes Speaking): Hire a tutor on: – Preply: http://tracking.preply.com/SH2X – Cambly: http://cambly.com – iTalki: http://italki.com Talk out loud. Narrate your life. Record yourself and play it back. Put words in your dictionary. Spend the rest of your hour: – Reading out loud. – Singing out loud. – Shadowing or mimicking actors from your TV show. FRIDAYS (Spend the Entire hour on Vocabulary): Review all the words in your dictionary. Write them out. Say them out loud. Use them in a sentence. Make a http://quizlet.com set. Make flashcards. Work until you have them all memorized. WEEKENDS: Find a new song. Find a new book. Find a new TV show. Take a break. References:https://www.youtube.com/watch?v=5-T6Xqlh6BU&amp;t=283s","categories":[{"name":"English","slug":"English","permalink":"https://hehehuang.github.io/categories/English/"}],"tags":[]},{"title":"Write an article","slug":"Write-an-artical","date":"2022-09-24T08:56:07.000Z","updated":"2022-09-24T09:43:02.358Z","comments":true,"path":"2022/09/24/Write-an-artical/","link":"","permalink":"https://hehehuang.github.io/2022/09/24/Write-an-artical/","excerpt":"","text":"Five step to write an article1. Ask a question2. Write a thesis statement (answer the question)3. Write an introductionHow to write an introduction Grabbers (attention) Joke Proverb&#x2F;quote anecdote surprising fact curiosity(?) Topic(subject) -what reasons(or main ideas) (3) Thesis -argument whether the topic is negative and positive 5w1h 4. Prove your thesisEssay Body (Structure) How to write an paragraph Topic sentence &amp; Closing sentence identifies the topic states what will be said about the topic Specific details &amp; supporting facts Specific details &amp; supporting faccts （for example: Facts, example from a source) Your thinking about the facts your own thoughts about the details &amp; facts (analogy, analysis, interpretation or explanation of facts) 5. Write your conclusion6. Extra Topichow to write a summarizehow to write a comment Reference:https://www.youtube.com/watch?v=Mwv3OlYojWw&amp;t=505s https://www.youtube.com/watch?v=IN6IOSMviS4 https://www.youtube.com/watch?v=jLdvEFtUuMM&amp;t=56s","categories":[{"name":"English","slug":"English","permalink":"https://hehehuang.github.io/categories/English/"}],"tags":[{"name":"Writing","slug":"Writing","permalink":"https://hehehuang.github.io/tags/Writing/"}]},{"title":"Machine Learning","slug":"Machine-Learning","date":"2022-09-23T13:04:19.000Z","updated":"2022-09-23T13:04:19.039Z","comments":true,"path":"2022/09/23/Machine-Learning/","link":"","permalink":"https://hehehuang.github.io/2022/09/23/Machine-Learning/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"Data Analysis with Pyspark","slug":"Data-Analysis-with-Pyspark","date":"2022-09-23T10:25:22.501Z","updated":"2022-09-23T10:36:13.511Z","comments":true,"path":"2022/09/23/Data-Analysis-with-Pyspark/","link":"","permalink":"https://hehehuang.github.io/2022/09/23/Data-Analysis-with-Pyspark/","excerpt":"","text":"","categories":[{"name":"Data Analysis","slug":"Data-Analysis","permalink":"https://hehehuang.github.io/categories/Data-Analysis/"}],"tags":[{"name":"PySpark","slug":"PySpark","permalink":"https://hehehuang.github.io/tags/PySpark/"}]},{"title":"Data Analysis with SQL","slug":"Data-Analysis-with-SQL","date":"2022-09-23T10:24:38.833Z","updated":"2022-09-23T10:36:39.635Z","comments":true,"path":"2022/09/23/Data-Analysis-with-SQL/","link":"","permalink":"https://hehehuang.github.io/2022/09/23/Data-Analysis-with-SQL/","excerpt":"","text":"","categories":[{"name":"Data Analysis","slug":"Data-Analysis","permalink":"https://hehehuang.github.io/categories/Data-Analysis/"}],"tags":[{"name":"SQL","slug":"SQL","permalink":"https://hehehuang.github.io/tags/SQL/"}]},{"title":"Data Analysis with Python","slug":"Data-Analysis-with-Python","date":"2022-09-23T10:24:12.280Z","updated":"2022-09-23T10:37:04.870Z","comments":true,"path":"2022/09/23/Data-Analysis-with-Python/","link":"","permalink":"https://hehehuang.github.io/2022/09/23/Data-Analysis-with-Python/","excerpt":"","text":"","categories":[{"name":"Data Analysis","slug":"Data-Analysis","permalink":"https://hehehuang.github.io/categories/Data-Analysis/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://hehehuang.github.io/tags/Python/"}]},{"title":"Python OOP","slug":"Python OOP","date":"2022-09-23T10:22:54.991Z","updated":"2022-09-23T10:23:04.903Z","comments":true,"path":"2022/09/23/Python OOP/","link":"","permalink":"https://hehehuang.github.io/2022/09/23/Python%20OOP/","excerpt":"","text":"","categories":[{"name":"Python","slug":"Python","permalink":"https://hehehuang.github.io/categories/Python/"}],"tags":[]},{"title":"Python Basic","slug":"Python Basic","date":"2022-09-23T10:21:30.629Z","updated":"2022-09-28T11:38:00.396Z","comments":true,"path":"2022/09/23/Python Basic/","link":"","permalink":"https://hehehuang.github.io/2022/09/23/Python%20Basic/","excerpt":"","text":"opening quotation mark, brace Stringusing variable in string 1full_name = f&#x27;&#123;first_name&#125;&#123;last_name&#125;&#x27; adding whitespce to string with tabs or newlines 123print(&#x27;\\tPython&#x27;)\\t means tabs\\n means newlines stripping 1Stripping syntax error : indicates that interpreter doesn’t recognize something in the code as valid python code. for example: 123# before python 3.6print(f&#x27;&#123;name&#125;&#x27;) # it will causing the syntax error, because interpreter doesn&#x27;t recoginize the code. Numberprecisely decimal Underscores in Numbers Multiple Assignment Constants Listmanipulating the listchanging, 1name[0]= &#x27;hh&#x27; add, 123# append# insert removing 1234# del# remove(&#x27;hh&#x27;)# pop() Oranizing the listsorting a list Permanently sorting a list temporarily printing a list in reverse order finding the length of a list intentional error Looping through an entire list a closer look at looping make numerical lists range() 1 list comprehensions working with part of a list slicing a list copy a list loop list TupleIf statementDictionaryWhile loopsFunctionClassesFiles and ExceptionTesting your codebuild in data type If statementWhile StatementReference:&lt;&gt;","categories":[{"name":"Python","slug":"Python","permalink":"https://hehehuang.github.io/categories/Python/"}],"tags":[]},{"title":"Array & Linked List","slug":"Array & Linked List","date":"2022-09-23T10:20:09.606Z","updated":"2022-09-23T10:20:32.597Z","comments":true,"path":"2022/09/23/Array & Linked List/","link":"","permalink":"https://hehehuang.github.io/2022/09/23/Array%20&%20Linked%20List/","excerpt":"","text":"","categories":[{"name":"Python","slug":"Python","permalink":"https://hehehuang.github.io/categories/Python/"}],"tags":[{"name":"Data Structure","slug":"Data-Structure","permalink":"https://hehehuang.github.io/tags/Data-Structure/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://hehehuang.github.io/tags/Algorithm/"}]},{"title":"Data Engineer","slug":"Data Engineer","date":"2022-09-23T10:12:25.135Z","updated":"2022-09-23T10:16:35.833Z","comments":true,"path":"2022/09/23/Data Engineer/","link":"","permalink":"https://hehehuang.github.io/2022/09/23/Data%20Engineer/","excerpt":"","text":"Data Engineer What is Data Engineer? What is main duly for data engineer? how data engineer work with AWS? what can i learn for data engineer? Big Data: data pipeline, Cloud service","categories":[{"name":"Big Data","slug":"Big-Data","permalink":"https://hehehuang.github.io/categories/Big-Data/"},{"name":"Cloud Service","slug":"Big-Data/Cloud-Service","permalink":"https://hehehuang.github.io/categories/Big-Data/Cloud-Service/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"https://hehehuang.github.io/tags/AWS/"},{"name":"Data Warehouse","slug":"Data-Warehouse","permalink":"https://hehehuang.github.io/tags/Data-Warehouse/"},{"name":"NoSQL","slug":"NoSQL","permalink":"https://hehehuang.github.io/tags/NoSQL/"},{"name":"Data Pipeline","slug":"Data-Pipeline","permalink":"https://hehehuang.github.io/tags/Data-Pipeline/"}]},{"title":"Tree","slug":"Tree","date":"2022-09-22T08:36:43.586Z","updated":"2022-09-22T08:42:39.475Z","comments":true,"path":"2022/09/22/Tree/","link":"","permalink":"https://hehehuang.github.io/2022/09/22/Tree/","excerpt":"","text":"Tree is the basic data Structure 12def searchTree():","categories":[{"name":"Python","slug":"Python","permalink":"https://hehehuang.github.io/categories/Python/"}],"tags":[{"name":"Data Structure","slug":"Data-Structure","permalink":"https://hehehuang.github.io/tags/Data-Structure/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://hehehuang.github.io/tags/Algorithm/"}]},{"title":"Sorting","slug":"Sorting","date":"2022-09-22T08:34:21.026Z","updated":"2022-09-22T08:42:36.580Z","comments":true,"path":"2022/09/22/Sorting/","link":"","permalink":"https://hehehuang.github.io/2022/09/22/Sorting/","excerpt":"","text":"sorting is algorithm to sort list in order. There are ten basic algorithm:","categories":[{"name":"Python","slug":"Python","permalink":"https://hehehuang.github.io/categories/Python/"}],"tags":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://hehehuang.github.io/tags/Algorithm/"}]},{"title":"AWS","slug":"AWS","date":"2022-09-19T17:45:57.203Z","updated":"2022-09-25T07:52:00.000Z","comments":true,"path":"2022/09/20/AWS/","link":"","permalink":"https://hehehuang.github.io/2022/09/20/AWS/","excerpt":"","text":"What is AWS?AWS is the cloud computing platform. computing: the bussiness requirement platform: provides the software like database and hardware: computing resource for example: Client want to deploy an web application. he just give money and offer the requirement to cloud computing platform and cloud computing platform will provide a series of services to deploy this web application. What is AWS with Big Data ecosystemAWS service: - Saas: software as a service RDS: amazon relational database service DynamoDB: K-V type NOSQL Redshift: Data warehouse (PostgreSQ) AWS Glue: ETL tool EMR: the Hadoop of AWS Kinesis: Stream process - Paas: Platform as a service S3: Amazon simple storge service &#x3D; HDFS AWS deep learning cloud watch &amp; cloud watch log - Iaas: Infrustructure as a service EC2 &#x3D; VMware VPC AWS Direct connect","categories":[{"name":"Big Data","slug":"Big-Data","permalink":"https://hehehuang.github.io/categories/Big-Data/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"https://hehehuang.github.io/tags/AWS/"}]},{"title":"Hadoop","slug":"Hadoop","date":"2022-09-19T17:45:57.203Z","updated":"2022-09-24T10:01:40.566Z","comments":true,"path":"2022/09/20/Hadoop/","link":"","permalink":"https://hehehuang.github.io/2022/09/20/Hadoop/","excerpt":"","text":"What is HadoopHadoop &#x3D; HDFS + MapReduce Why need Hadoop?because the cpu, distrbution computing. what is changes History of HadoopHadoop 1.0Hadoop 2.0Hadoop 3.0HDFSMapReducehow data is processed in MapReduce Map stage + Reduce shuffling in Partition the number of partitioner is decide by the number of Reduce task","categories":[{"name":"Big Data","slug":"Big-Data","permalink":"https://hehehuang.github.io/categories/Big-Data/"}],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://hehehuang.github.io/tags/Hadoop/"},{"name":"Mapreduce","slug":"Mapreduce","permalink":"https://hehehuang.github.io/tags/Mapreduce/"}]},{"title":"PySpark","slug":"PySpark","date":"2022-09-19T17:45:57.203Z","updated":"2022-09-25T12:46:25.000Z","comments":false,"path":"2022/09/20/PySpark/","link":"","permalink":"https://hehehuang.github.io/2022/09/20/PySpark/","excerpt":"","text":"What is Spark?Spark is a data processing engine for big data sets. Pyspark is that Spark can be call by python language. why need Spark?Advantages of spark handle many case: SparkSQL(dataframe) for data analysis Spark streaming for real-time analysis Spark Ml for machine learning work with many source Standalone, Hadoop, K8s,AWS better than Mapreduce, enhancement to mapreduce (in real-time processing) Why Spark is better than Mapreduce in terms of efficiency Mapreduce takes input from the HDFS, each map task process it , keeps in memory ,if exceed the default 100MB(io.sort.mb), then it split to disk.reduce task take data from disk and continue to process it. Spark uses random access memory (RAM) to cache and process data instead of a file system. Spark creates a Directed Acyclic Graph (DAG) to schedule tasks and the orchestration of nodes across the Hadoop cluster. How Spark work in cluster?HDFS,Yarn,Spark HDFS: Name node, Data Node Yarn: Resource Manager, Node Manager Spark: Driver, Worker when spark start to work, it need HDFS to provide the data and Yarn to provide computing resource. Spark RDDFeatures: partitions distributed in cluster computing each split dependencies on each RDDs (lineage) Key-value RDDs have Partioner sent computing to data Two step in RDD: Transform: transform one RDD to another RDD 123456789from pyspark import SparkContextfrom pyspark import SparkConfconf = SparkConf()sc = SparkContext(conf=conf)rdd1 = sc.parallelize([1,2,3,4])rdd2 = rdd1.map(lambda x: x+1) Action: take action for the RDD, normally, the output will be value 1result = rdd2.collect() RDD Persistence and Caching Mechanismif there are two actions in an spark application. 123456rdd1 = sc.textfile(//:HDFS..)rdd2 = sc.map(lambda x: x+1)# one action rdd3 = rdd2.count()# another actionrdd4 = rdd2.count() one action means one job in spark application. the rdd will be released in memory, which is that rdd3 will be cleaned. the rdd4 is the result of action at the rdd2. it will be causing that the re-calculation of rdd2. for this senaria, we need the RDD Persistence and cache to save our time and cost. serveral caching mechanism is available. Spark narrow and wide transformationNarrow transformation provides one to one transformation which there is no shuffling of data cross the nodes (every node do their own work can the results are concatenated). Some examples of narrow transformation include: map(), flatMap(), filter(), sample(), union(). For wide transformation, all the elements are required to do the operation. Partition live in many partitions of parent RDD which results in shuffling of data across the nodes. Some examples of wide transformation include: intersection(), distinct(), groupByKey(), reduceByKey(). Spark CoreSpark SqlSpark StreamingSpark MLReferencehttps://www.ibm.com/cloud/blog/hadoop-vs-spark https://learn.microsoft.com/en-us/azure/hdinsight/spark/apache-spark-streaming-high-availability https://cedricyf.medium.com/get-started-on-apache-pyspark-part-2-15d62494c18a","categories":[{"name":"Big Data","slug":"Big-Data","permalink":"https://hehehuang.github.io/categories/Big-Data/"}],"tags":[{"name":"Hadoop","slug":"Hadoop","permalink":"https://hehehuang.github.io/tags/Hadoop/"}]}],"categories":[{"name":"NLP","slug":"NLP","permalink":"https://hehehuang.github.io/categories/NLP/"},{"name":"English","slug":"English","permalink":"https://hehehuang.github.io/categories/English/"},{"name":"Data Analysis","slug":"Data-Analysis","permalink":"https://hehehuang.github.io/categories/Data-Analysis/"},{"name":"Python","slug":"Python","permalink":"https://hehehuang.github.io/categories/Python/"},{"name":"Big Data","slug":"Big-Data","permalink":"https://hehehuang.github.io/categories/Big-Data/"},{"name":"Cloud Service","slug":"Big-Data/Cloud-Service","permalink":"https://hehehuang.github.io/categories/Big-Data/Cloud-Service/"}],"tags":[{"name":"Deep Learning","slug":"Deep-Learning","permalink":"https://hehehuang.github.io/tags/Deep-Learning/"},{"name":"Writing","slug":"Writing","permalink":"https://hehehuang.github.io/tags/Writing/"},{"name":"PySpark","slug":"PySpark","permalink":"https://hehehuang.github.io/tags/PySpark/"},{"name":"SQL","slug":"SQL","permalink":"https://hehehuang.github.io/tags/SQL/"},{"name":"Python","slug":"Python","permalink":"https://hehehuang.github.io/tags/Python/"},{"name":"Data Structure","slug":"Data-Structure","permalink":"https://hehehuang.github.io/tags/Data-Structure/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://hehehuang.github.io/tags/Algorithm/"},{"name":"AWS","slug":"AWS","permalink":"https://hehehuang.github.io/tags/AWS/"},{"name":"Data Warehouse","slug":"Data-Warehouse","permalink":"https://hehehuang.github.io/tags/Data-Warehouse/"},{"name":"NoSQL","slug":"NoSQL","permalink":"https://hehehuang.github.io/tags/NoSQL/"},{"name":"Data Pipeline","slug":"Data-Pipeline","permalink":"https://hehehuang.github.io/tags/Data-Pipeline/"},{"name":"Hadoop","slug":"Hadoop","permalink":"https://hehehuang.github.io/tags/Hadoop/"},{"name":"Mapreduce","slug":"Mapreduce","permalink":"https://hehehuang.github.io/tags/Mapreduce/"}]}